---
title: "E1_report"
author: "Gabriel Strain"
date: "21/03/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(knitr.include_graphics.ext = TRUE)
```

# Performance on Correlation Estimation is Better on Larger Plots. In addition, the Presence of a Novel Contrast Encoding also Improves Performance.

## Plotting the Results

The plots below show subjective correlation performance for Small, Medium, and Large
plots. These sizes corresponded to 63%, 100% and 252% size ratios. We hypothesised
that performance at estimating correlation would be better when the plot was larger.
N = 118, 180 experimental trials per participant (fully repeated measures: all participants
saw all versions of each plot). 

```{r, include = FALSE, warning = FALSE, message =  FALSE}
library(tidyverse)
library(afex)
library(emmeans)
library(lme4)
library(buildmer)
library(gridExtra)
library(MASS)
library(scales)
library(lmerTest)

all_data <- read_csv("data/final_data.csv")

# separate the plots_with_labels column into 3 - item, size (3 levels), and present (2 levels)

separated_data <- 
  all_data %>%
  mutate(plots_with_labels = str_replace(plots_with_labels, pattern = "S", replacement = "-S-")) %>%
  mutate(plots_with_labels = str_replace(plots_with_labels, pattern = "M", replacement = "-M-")) %>%
  mutate(plots_with_labels = str_replace(plots_with_labels, pattern = "L", replacement = "-L-")) %>%
  separate(plots_with_labels, c("item", "size", "present"), sep = "-") %>%
  mutate(present = str_replace(present, pattern = ".png", replacement = "")) %>%
  mutate(item = str_replace(item, pattern = "all_plots/", replacement = "")) %>%
  dplyr::select(c("item", "size", "present", "participant",
           "q1_slider.response", "q2_slider.response",
           "q3_slider.response", "q4_slider.response",
           "q5_slider.response", "res_vec", "unique_item_no",
           "my_rs", "slider.response", "age")) %>%
  filter(unique_item_no < 181)

data_to_analyse <- separated_data  %>%
  mutate(size = as.factor(size)) %>%
  mutate(present = as.factor(present)) %>%
  mutate(difference = my_rs - slider.response) %>%
  filter(!is.na(difference)) %>%
  dplyr::select(-c(q1_slider.response:q5_slider.response))

literacy <- all_data%>%
  filter(!is.na(q1_slider.response)) %>%
  rowwise() %>%
  mutate(literacy = sum(c(q1_slider.response, 
                            q2_slider.response, 
                            q3_slider.response, 
                            q4_slider.response, 
                            q5_slider.response))) %>%
    dplyr::select(participant,
           literacy)

only_those_passed <- inner_join(data_to_analyse, literacy, by = "participant")
```

```{r, echo = FALSE, fig.width= 10, fig.height=3.33}
size_L <- only_those_passed %>%
  filter(size == "L") %>%
  group_by(item) %>%
  summarise(mean_obj = mean(my_rs),
            mean_subj = mean(slider.response), sd_subj = sd(slider.response)) %>%
  ggplot(aes(x = mean_obj, y = mean_subj)) +
  geom_point() +
  stat_smooth(method = "loess",
              se = FALSE) +
  geom_errorbar(aes(ymin = mean_subj-sd_subj, ymax = mean_subj+sd_subj), width = .01, colour = "forestgreen") +
  geom_abline(intercept = 0, slope = 1) +
  xlim(0,1) +
  ylim(0,1) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(x = "Objective Correlation Rating",
       y = "Subjective Correlation",
       title = "Large Plot")

size_M <- only_those_passed %>%
  filter(size == "M") %>%
  group_by(item) %>%
  summarise(mean_obj = mean(my_rs),
            mean_subj = mean(slider.response), sd_subj = sd(slider.response)) %>%
  ggplot(aes(x = mean_obj, y = mean_subj)) +
  geom_point() +
  stat_smooth(method = "loess",
              se = FALSE) +
  geom_errorbar(aes(ymin = mean_subj-sd_subj, ymax = mean_subj+sd_subj), width = .01, colour = "forestgreen") +
  geom_abline(intercept = 0, slope = 1) +
  xlim(0,1) +
  ylim(0,1) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(x = "Objective Correlation Rating",
       y = "Subjective Correlation",
       title = "Medium Plot")
  
size_S <- only_those_passed %>%
  filter(size == "S") %>%
  group_by(item) %>%
  summarise(mean_obj = mean(my_rs),
            mean_subj = mean(slider.response), sd_subj = sd(slider.response)) %>%
  ggplot(aes(x = mean_obj, y = mean_subj)) +
  geom_point() +
  stat_smooth(method = "loess",
              se = FALSE) +
  geom_errorbar(aes(ymin = mean_subj-sd_subj, ymax = mean_subj+sd_subj), width = .01, colour = "forestgreen") +
  geom_abline(intercept = 0, slope = 1) +
  xlim(0,1) +
  ylim(0,1) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(x = "Objective Correlation Rating",
       y = "Subjective Correlation",
       title = "Small Plot")

final_plot <- grid.arrange(size_S, size_M, size_L, ncol = 3, top = "Comparing Correlation Ratings by Plot Size") 
```

The summary statistics for the factor of size are as follows.

```{r, echo = FALSE}
only_those_passed  %>%
  mutate(size = as.factor(size)) %>%
  mutate(present = as.factor(present)) %>%
  mutate(difference = my_rs - slider.response) %>%
  filter(!is.na(size)) %>%
  filter(!is.na(difference)) %>%
  group_by(size) %>%
  summarise(mean = mean(difference), sd = sd(difference))
```

We utilised a novel contrast encoding whereby the contrast of a certain point was 
linearly related to the size of the residual of that point. The presence of this 
contrast encoding was associated with better performance on correlation estimation.
Summary statistics are below the plots.

```{r, echo = FALSE, fig.height=5, fig.width=10}
present <- only_those_passed %>%
  filter(present == "Y") %>%
  group_by(item) %>%
  summarise(mean_obj = mean(my_rs),
            mean_subj = mean(slider.response), sd_subj = sd(slider.response)) %>%
  ggplot(aes(x = mean_obj, y = mean_subj)) +
  geom_point() +
  stat_smooth(method = "loess",
              se = FALSE) +
  geom_errorbar(aes(ymin = mean_subj-sd_subj, ymax = mean_subj+sd_subj), width = .01, colour = "forestgreen") +
  geom_abline(intercept = 0, slope = 1) +
  xlim(0,1) +
  ylim(0,1) +
  theme_minimal() +
  labs(x = "Objective Correlation Rating",
       y = "Subjective Correlation",
       title = "Encoding Present")

absent <- only_those_passed %>%
  filter(present == "N") %>%
  group_by(item) %>%
  summarise(mean_obj = mean(my_rs),
            mean_subj = mean(slider.response), sd_subj = sd(slider.response)) %>%
  ggplot(aes(x = mean_obj, y = mean_subj)) +
  geom_point() +
  stat_smooth(method = "loess",
              se = FALSE) +
  geom_errorbar(aes(ymin = mean_subj-sd_subj, ymax = mean_subj+sd_subj), width = .01, colour = "forestgreen") +
  geom_abline(intercept = 0, slope = 1) +
  xlim(0,1) +
  ylim(0,1) +
  theme_minimal() +
  theme(plot.title = element_text(hjust =0.9)) +
  labs(x = "Objective Correlation Rating",
       y = "Subjective Correlation",
       title = "Encoding Absent")   

final_plot <- grid.arrange(present, absent,ncol = 2, top = "Comparing Correlation Ratings")  
```

```{r, echo = FALSE}
only_those_passed %>%
  mutate(size = as.factor(size)) %>%
  mutate(present = as.factor(present)) %>%
  mutate(difference = my_rs - slider.response) %>%
  filter(!is.na(size)) %>%
  filter(!is.na(difference)) %>%
  group_by(present) %>%
  summarise(mean = mean(difference), sd = sd(difference))
```

# Modelling

## Modelling Main Effects

A Linear Mixed Model was fitted with the **buildmer** package, which begins with
a maximal model and drops terms until it converges and no errors are returned.
The model built had the following syntax;

```
model <- lmer(difference ~ size * present + (1 | participant) + (1 | item))
```

This model has random intercepts for participants and items.

```{r, include = FALSE}
contrasts(only_those_passed$size) = contr.sum(levels(only_those_passed$size))
contrasts(only_those_passed$present) = contr.sum(levels(only_those_passed$present))

model <- lmer(difference ~ size * present +
       (1 | participant) +
       (1 | item),
     data = only_those_passed)

model_null <- lmer(difference ~ 1 +
       (1 | participant) +
       (1 | item),
     data = only_those_passed)

anova(model, model_null)
```

## Checking Presence of Interaction

```{r, echo = FALSE}
model_no_interact <- lmer(difference ~ size + present +
       (1 | participant) +
       (1 | item),
     data = only_those_passed)

anova(model, model_no_interact)
```

There was no significant difference between models with and without the interaction.

An ANOVA comparing models with and without our interventions revealed a significant
effect $\chi^2(5)=91.91, p < .0001$. This effect was driven ratings being significantly 
higher for Large vs Small plots ($p = .001$) and Medium vs Small plots ($p = .025$), 
and being higher when the contrast encoding was employed ($p < .0001$).

```{r, echo = FALSE}
summary(model)
```


There was no effect of an interaction between the two factors. Estimated marginal
means and contrasts for the two factors can be seen below:

```{r, echo=FALSE, warning=FALSE, message=FALSE}
emmeans(model, pairwise ~ size)
emmeans(model, pairwise ~ present)
```

## Modelling with Graph Literacy as a Fixed Effect

Participants also answered a 5-item questionnaire on Subjective Graph Literacy 
(Garcia-Retamero et al., 2016). We build a model with graph literacy as a fixed effect

```{r, include = FALSE}
model_lit <- lmer(difference ~ literacy + size * present +
       (1 | participant) +
       (1 | item),
     data = only_those_passed)

anova(model_lit, model)
```
  
An ANOVA between the model including literacy as a fixed effect and the original 
model reveals no significant effect of graph literacy: $\chi^2(1)=2.33, p = 0.13$.

## Modelling with Residuals

As two scatterplots can show the same correlations, but have different point-by-point 
residuals, we can also model to include the sum of the residuals as a predictor.

```{r, include = FALSE}
model_res <- lmer(difference ~ res_vec + size * present +
       (1 | participant) +
       (1 | item),
     data = only_those_passed)

anova(model_res, model)
```

An ANOVA between the model including total residuals as a fixed effect and the original
model reveals no significant effect of total residual size for each plot: $\chi^2(1) = 2.31, p = 0.13$.

# Where Next?

## Residual Slopes

The plot below is of the type used in E1. 
```{r, echo = FALSE, warning=FALSE, fig.align='center'}
set.seed(1234)

my_sample_size = 128

my_desired_r = 0.8

mean_variable_1 = 0
sd_variable_1 = 1

mean_variable_2 = 0
sd_variable_2 = 1

mu <- c(mean_variable_1, mean_variable_2) 

myr <- my_desired_r * sqrt(sd_variable_1) * sqrt(sd_variable_2)

mysigma <- matrix(c(sd_variable_1, myr, myr, sd_variable_2), 2, 2) 

corr_data = as_tibble(mvrnorm(my_sample_size, mu, mysigma, empirical = TRUE))

corr_model <- lm(V2 ~ V1, data = corr_data)

my_residuals <- abs(residuals(corr_model))

data_with_resid <- round(cbind(corr_data, my_residuals), 2)

ggplot(data_with_resid, aes(x = V1, y = V2)) +
  geom_point(aes(alpha = -my_residuals))  +
  #geom_smooth(method = "lm", se = FALSE) +
  labs(x = "", y = "") +
  theme_classic() +
  theme(axis.text = element_blank()) +
  theme(legend.position = "None")
```

With this method, the residuals for each point were scaled between 0 and 1, and 
used as the contrast for that point. The issue with this, as we only realised after
analysing the results of the first experiment, is that there is no direct mapping of
residual size to contrast for a point. The highest residual for a particular point 
had the lowest contrast, and vice versa.

In order to fix this, instead of scaling between 0 and 1, we propose
performing a transformation on the raw residual itself so that it is 
between 0 and 1, and then using this transformed residual as the contrast value.

The plot below illustrates what we are now calling the decay parameter, both 
with a linear decay, and with several non-linear functions. The non-linear functions
take the formula $y = 1-(a)^x$, where $a < 1$ and $x = residual$. Because the lowest
*r* value (and therefore plot with the highest residuals) used is 0.2, that has been 
used to illustrate the different parameters of the decay function.

```{r, echo = FALSE, warning=FALSE, fig.align='center', out.width="80%"}
library(MASS)

set.seed(1234)

my_desired_r = 0.2
  
my_sample_size = 128

mean_variable_1 = 0
sd_variable_1 = 1

mean_variable_2 = 0
sd_variable_2 = 1

mu <- c(mean_variable_1, mean_variable_2) 

myr <- my_desired_r * sqrt(sd_variable_1) * sqrt(sd_variable_2)

mysigma <- matrix(c(sd_variable_1, myr, myr, sd_variable_2), 2, 2) 

corr_data = as_tibble(mvrnorm(my_sample_size, mu, mysigma, empirical = TRUE))

corr_model <- lm(V2 ~ V1, data = corr_data)

my_residuals <- abs(residuals(corr_model))

data_with_resid <- round(cbind(corr_data, my_residuals), 2)

slopes <- data_with_resid %>%
  mutate(decay_linear = my_residuals/3.2) %>%
  mutate(decay_0.125 = 1-(0.125)^my_residuals) %>%
  mutate(decay_0.25 = 1-(0.25)^my_residuals) %>%
  pivot_longer(cols = starts_with("de"),
               names_to = c("decay"),
               values_to = "transformed_residual")

slopes %>%
  ggplot(aes(x = my_residuals, y = transformed_residual)) +
  geom_line(aes(colour = decay)) +
  labs(x = "Residual",
       y = "Contrast Value",
       title = "Decay Parameters")
```
 
Below are scatterplots all with *r* = 0.6, each labelled with the decay
parameter used.

```{r,echo = FALSE, warning=FALSE, fig.align='center'}
  set.seed(1234)
  
  my_sample_size = 128
  
  my_desired_r = 0.6
  
  mean_variable_1 = 0
  sd_variable_1 = 1
  
  mean_variable_2 = 0
  sd_variable_2 = 1
  
  mu <- c(mean_variable_1, mean_variable_2) 
  
  myr <- my_desired_r * sqrt(sd_variable_1) * sqrt(sd_variable_2)
  
  mysigma <- matrix(c(sd_variable_1, myr, myr, sd_variable_2), 2, 2) 
  
  corr_data = as_tibble(mvrnorm(my_sample_size, mu, mysigma, empirical = TRUE))
  
  corr_model <- lm(V2 ~ V1, data = corr_data)
  
  my_residuals <- abs(residuals(corr_model))
  
  data_with_resid <- round(cbind(corr_data, my_residuals), 2)
  
  slopes <- data_with_resid %>%
  mutate(slope_linear = my_residuals/3.2) %>%
  mutate(slope_0.125 = 1-(0.125)^my_residuals) %>%
  mutate(slope_0.25 = 1-(0.25)^my_residuals) %>%
  mutate(slope_0.5 = 1-(0.5)^my_residuals)

p.125 <- ggplot(slopes, aes(x = V1, y = V2)) +
  scale_alpha_identity() +
  geom_point(aes(alpha = 1-slope_0.125))  +
  labs(x = "", y = "") +
  theme_classic() +
  theme(axis.text = element_blank()) +
  theme(plot.margin = unit(c(0,0,0,0), "cm")) +
  theme(legend.position = "None") +
  labs(title = "Steepest Decay (a = 0.125)")
  

p.25 <- ggplot(slopes, aes(x = V1, y = V2)) +
  scale_alpha_identity() +
  geom_point(aes(alpha = 1-slope_0.25))  +
  labs(x = "", y = "") +
  theme_classic() +
  theme(axis.text = element_blank()) +
  theme(plot.margin = unit(c(0,0,0,0), "cm")) +
  theme(legend.position = "None") +
  labs(title = "Flatter Decay (a = 0.25)")

p.linear <- ggplot(slopes, aes(x = V1, y = V2)) +
  scale_alpha_identity() +
  geom_point(aes(alpha = 1-slope_0.5))  +
  labs(x = "", y = "") +
  theme_classic() +
  theme(axis.text = element_blank()) +
  theme(plot.margin = unit(c(0,0,0,0), "cm")) +
  theme(legend.position = "None") +
  labs(title = "Linear Decay")

p.none <- ggplot(slopes, aes(x = V1, y = V2)) +
  #scale_alpha_identity() +
  geom_point()  +
  labs(x = "", y = "") +
  theme_classic() +
  theme(axis.text = element_blank()) +
  theme(plot.margin = unit(c(0,0,0,0), "cm")) +
  theme(legend.position = "None") +
  labs(title = "No Decay")

final_plot <- grid.arrange(p.125, p.25, p.linear, p.none, ncol = 2) 
```

## Addressing Issues of Data Quality

Despite collecting data from over 260 participants, only 118 remained after rejecting
those who failed the attention checks. These attention checks were confirmed as
fair by the team at prolific.co, but on the whole this made data collection more
difficult and time-consuming than we had originally anticipated. Below are
examples of experimental (left) and attention check (right) trials. 

```{r trial, echo=FALSE, fig.cap="", out.width = "100%", out.height="25%", fig.show='hold', fig.align='center'}
knitr::include_graphics(c("proposed_trial_amendments/trial.png", "proposed_trial_amendments/set_to_1_AC.png"))
```

To address the issues of data quality, I propose we increase the salience of the
attention check trials by conditioning participants to read some text before
they see the plot and set the slider. In the proposed methodology, participants
would see text for each slide *before* the plot was displayed.

```{r new_normal_trial, echo=FALSE, fig.cap="", out.width = "100%", fig.show='hold', fig.align='center'}
knitr::include_graphics("proposed_trial_amendments/normal_trial.png")
```

Below shows the new proposed attention check trials. Red font has been used to 
draw participants' attention.

```{r at_trial, echo=FALSE, fig.cap="", out.width = "100%", fig.show='hold', fig.align='center'}
knitr::include_graphics("proposed_trial_amendments/at_trial.png")
```








